{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assingment 4: Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will train a binary classifier for predicting whether a patient's breast tumor is malignant or  benign. You will be provided a data set with tumor traits. This data set is available in scikit-learn.\n",
    "\n",
    "Your task is to train and build a classifier  by following the steps below.\n",
    "\n",
    "Implement all tasks in your notebook and submit your notebook ipynb file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1  (25 points)\n",
    "\n",
    "**Task 1A**: Build a decision tree classifier by creating a single random training and testing dataset. Your training set should be 80% of your original sample set. Visualize your decision tree and report its accuracy on your testing dataset. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Task 1.B:** Evaluate the performance of your classsifer over 10 random training/test sets (of equal size) and report all accuracy values you collected as well as the average accuracy. (15 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.C:** Compare the accuracy your observed with each of the two approaches (are they similar/different, how accuracy flunctuates, etc). (5points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (25 points) \n",
    "\n",
    "**Task 2.A:** Perform 10-fold cross validation to explore how the max_depth and the min_samples parameter of your classifer affect its accuracy.  You are NOT allowed to use the grid search function for this task. You should try tree depths values ranging from 1 to 20 and min samples at leaf that range from 1 to 10. (10points, 5 for each parameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (25 points) \n",
    "\n",
    "**Task 2.B:** Plot 2 boxplot graphs  that show how each of these parameters affect the accuracy. (5 points each plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Task 2.C:** Use the training and testing set we provided to test the classifier with the best max_depth and min_samples_leaf parameters you discovered as well as classifier that use the default parameters for a decision tree. Which one is performing better in terms of accuracy? (5points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 (25 points) \n",
    "\n",
    "Perform a nested cross validation to explore how  different classification algorithms perform on this task. You should try random tree forest and kNN.  All of them could be validated through 5-fold validation and you should use the  grid search function available in sklearn for your internal cross validation. Discuss which classifier performed better. It is up to you which parameters you use in your grid search but keep in mind that the more parameter you use the longer the execution time. To help you TAs grading this part we ask that you restrict your exploration to a singe parameter per model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (25 points)\n",
    "\n",
    "Once you identify your best classifier, train it on the training set we provided and report the confusion matric, the recall and precision of it on the test set we provided.  You should also report  the F1-score.  The F1 score, commonly used in information retrieval, measures accuracy using the statistics precision *p* and recall *r*. The F1 score is given by:\n",
    "\n",
    "$F1 = 2\\frac{p \\cdot r}{p+r}\\ \\ \\mathrm{where}\\ \\ p = \\frac{tp}{tp+fp},\\ \\ r = \\frac{tp}{tp+fn}$\n",
    "\n",
    "The F1 metric weights recall and precision equally, and a good retrieval algorithm will maximize both precision and recall simultaneously. Thus, moderately good performance on both will be favored over extremely good performance on one and poor performance on the other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
