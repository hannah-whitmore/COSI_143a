{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Programming Assignment 5: Entity Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this assignment you are give a  dataset that contains product data from Walmart and Amazon. The dataset contains two tables the left table (denoted by *ltable*), and the right table (denoted by *rtable*). Further, we are providing a dataset (*test.csv*) that contains a list of true product matches and no-matches for evaluation.\n",
    "\n",
    "Table ltable has the following schema: ltable_id, title, category, brand, modelno, price\n",
    "\n",
    "Table rtable has the following schema: rtable_id, title, category, brand, modelno, price\n",
    "\n",
    "The testing data file has the following schema: ltable_id, rtable_id, label, id \n",
    "\n",
    "In the testing data file the label is 0 if the two products do not match and 1 if they match. \n",
    "\n",
    "*Helpful hint: to read the two tables you will need to use the encoding latin-1*\n",
    "\n",
    "For this task you will need to solve the problem of entity matching over the provided records of products and then report the performance of your solution when evaluated on the testing dataset. \n",
    "\n",
    "You are expected to submit a notebook that implements the following:\n",
    "\n",
    "1. Implement an entity matching solution between the two tables, using the Record linkage toolkit we introduced in class.\n",
    "  + You can use any index you need as long as your notebook can be executed within a reasonable time frame. **Entity matching code that takes more than 5 mins to run will be getting zero points**. You can measure the time it takes for a cell to execute by using the command <code> %%time* </code> as the first line of your cell. \n",
    "  + *Hint* : A full index will take a long time to execute. You should be mindful of the number of product comparisons your code will execute. A blocked index on the other hand might miss some identical products if it looking for matches on the \"wrong\" set of attributes, if it is looking for exact strings vs similar strings, if the matching threshold is set to be too high, etc. You could use any of the indexing techniques we discussed in class or any others that you see fit based on the documentation of the [Record linkage toolkit](https://recordlinkage.readthedocs.io/en/latest/about.html) \n",
    "  \n",
    "2. Report the final prediction for your matches in an output csv file that has the schema <ltable_id, rtable_id, prediction>. First line should have be this: ltable_id,rtable_id,prediction. Name your output file output.csv. \n",
    "  + Prediction should have the value 1 if the two products match and 0 otherwise. Include the output file in your submittion. \n",
    "  + How you decide the final prediction depends on the approach you used (and your intuition). For instance, if you are using 3 strings (title, category, brand) for your matching then you needs to decide if two products match if they agree on all or some of these 3 strings. \n",
    "  \n",
    "3. Report the false positives and false negatives by comparing your matches with the ground truth (which is in the testing dataset test.csv we provided). You should also report the precision and recall of your solution and the F1 measure. \n",
    "  + We will also test the F1 measure of your matches. **The top-5 F1 measures in class will get 10 extra credit points**. This assignment is a competition!  Our solution got a 0.76 F1 measure but you could possibly do even better.  \n",
    "  + Note: some of the product matches  (pairs of <ltable_id, rtable_id) > that appear in the test file we provided (the ground truth), might not appear in your  output of your and vice versa. We are asking you to evaluate the F1 measure in the intersection of those two sets. \n",
    "  \n",
    "4. Describe in a markdown cell in your notebook the process you used for your solution. Why did you choose the specific index, why the specific attributes (if any) for your blocked index, why did you use or not the SortedNeighborhood algorithm for your index. We want to understand the process you used and we expect it to be  a bit more sophisticated  than  a random pick of parameters. In other words - defend your notebook! \n",
    "\n",
    "Good luck! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
